{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bc58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "===========\n",
    "Description\n",
    "===========\n",
    "Simple script to copy and gzip static web files to an AWS S3 bucket. S3 is great for cheap hosting of static web content, but by default it does not gzip CSS and JavaScript, which results in much larger data transfer and longer load times for many applications\n",
    "When using this script CSS and JavaScript files are gzipped in transition, and appropriate headers set as per the technique described here: http://www.jamiebegin.com/serving-compressed-gzipped-static-files-from-amazon-s3-or-cloudfront/\n",
    "* Files overwrite old versions\n",
    "* Orphaned files are not deleted\n",
    "* S3 will not negotiate with clients and will always serve the gzipped version, so user agents must be able to understand the Content-Encoding:gzip header (all modern web browsers can)\n",
    "=============\n",
    "Prerequisites\n",
    "=============\n",
    "Python >= v2.7\n",
    "boto\n",
    "install with pip:\n",
    "    pip install boto\n",
    "or with apt-get\n",
    "    apt-get install python-boto\n",
    "=====\n",
    "Usage\n",
    "=====\n",
    "From the command line\n",
    "    python deploy_to_s3.py --directory source-dir --bucket bucket-name\n",
    "The standard boto environment variables AWS_SECRET_ACCESS_KEY and AWS_ACCESS_KEY_ID are used for authentication - see boto for details\n",
    "For help:\n",
    "    python deploy_to_s3.py --help\n",
    "\"\"\"\n",
    "\n",
    "#!/usr/bin/python\n",
    "__author__ = 'rob@redanorak.co.uk'\n",
    "\n",
    "import os, sys, argparse, tempfile, gzip\n",
    "from boto.s3.connection import S3Connection\n",
    "from boto.s3.key import Key\n",
    "\n",
    "def add_file(source_file, s3_key):\n",
    "    \"\"\"write a file to an s3 key\"\"\"\n",
    "    if source_file.endswith(\".js\") or source_file.endswith(\".css\"):\n",
    "        print(\"gzipping %s to %s\" %(source_file, s3_key.key))\n",
    "        gzip_to_key(source_file, s3_key)\n",
    "    else:\n",
    "        print(\"uploading %s to %s\" %(source_file, s3_key.key))\n",
    "        s3_key.set_contents_from_filename(source_file)\n",
    "\n",
    "def gzip_to_key(source_file, key):\n",
    "    tmp_file = tempfile.NamedTemporaryFile(mode=\"wb\", suffix=\".gz\", delete=False)\n",
    "    with open(source_file, 'rb') as f_in:\n",
    "        with gzip.open(tmp_file.name, 'wb') as gz_out:\n",
    "            gz_out.writelines(f_in)\n",
    "    key.set_metadata('Content-Type', 'application/x-javascript' if source_file.endswith(\".js\") else 'text/css')\n",
    "    key.set_metadata('Content-Encoding', 'gzip')\n",
    "    key.set_contents_from_filename(tmp_file.name)\n",
    "    os.unlink(tmp_file.name) #clean up the temp file\n",
    "\n",
    "def dir_to_bucket(src_directory, bucket):\n",
    "    \"\"\"recursively copy files from source directory to boto bucket\"\"\"\n",
    "    for root, sub_folders, files in os.walk(src_directory):\n",
    "        for file in files:\n",
    "            abs_path = os.path.join(root, file)\n",
    "            rel_path = os.path.relpath(abs_path, src_directory)\n",
    "            #get S3 key for this file\n",
    "            k = Key(bucket)\n",
    "            k.key = rel_path\n",
    "            add_file(abs_path, k)\n",
    "\n",
    "def main():\n",
    "    #get arguments\n",
    "    arg_parser = argparse.ArgumentParser(description='Deploy static web resources to an S3 bucket, gzipping JavaScript and CSS files in the process')\n",
    "    arg_parser.add_argument('-d','--directory', help='The source directory containing your static website files', required=True)\n",
    "    arg_parser.add_argument('-b','--bucket', help='The name of the bucket you wish to copy files to, the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variables are used for your credentials', required=True)\n",
    "    args = arg_parser.parse_args()\n",
    "\n",
    "    #connect to S3\n",
    "    conn = S3Connection()\n",
    "    target_bucket = conn.get_bucket(args.bucket, validate=False)\n",
    "    dir_to_bucket(args.directory, target_bucket)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
